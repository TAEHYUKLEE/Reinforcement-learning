{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-24c8574c5a40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeque\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdqn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;31m# Bring in subpackages.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAUTOTUNE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mservice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdense_to_ragged_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdense_to_sparse_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfrom_dataset_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregister_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompression_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_options\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAutoShardPolicy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_options\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mExternalStatePolicy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\compression_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgen_experimental_dataset_ops\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mged_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensor_spec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtype_spec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensor_array_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mragged\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mragged_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf_logging\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "import random\n",
    "from collections import deque\n",
    "import dqn\n",
    "import Environment as En\n",
    "#from typing import List\n",
    "\n",
    "environment = En.env() #call environment\n",
    "#환경을 부른다. (사실 Environment라는 객체를 만든다)\n",
    "\n",
    "_ = environment.reset() #환경을 초기화한다.\n",
    "\n",
    "alpha = 0.9 #learning rate (based on Q)\n",
    "\n",
    "#Input & Output\n",
    "input_size = environment.state_num() #앞에서 환경을 초기화하고 환경 내에서는 state가 설정되고 input_size가 결정된다.\n",
    "output_size = environment.action_setting() #환경에서의 action들을 모두 정의한다.\n",
    "\n",
    "\n",
    "#Reinforcement learning parmeter\n",
    "dis = 0.99  \n",
    "buffer_memory = 50000 #Replay memory에 몇개를 넣을 것인가? (Buffer)\n",
    "batch_size = 100 #Mini batch size Buffer에서 몇개씩 batch로 만들어서 학습시킬 것인가?\n",
    "\n",
    "\n",
    "def replay_train(mainDQN_instance,targetDQN_instance, train_batch): #mainDQN: dqn.DQN, targetDQN: dqn.DQN, train_batch: list:\n",
    "   # 학습시킬 Network와 데이터 batch가 배달옴\n",
    "    Q_old = np.empty(0)\n",
    "    Q_new = np.empty(0)\n",
    "    \n",
    "    x_stack = np.empty(0)\n",
    "    y_stack = np.empty(0)\n",
    "    \n",
    "    x_stack = np.reshape(x_stack, (0, mainDQN_instance.input_size))\n",
    "    y_stack = np.reshape(y_stack, (0, mainDQN_instance.output_size)) \n",
    "    #print(\"train_Batch\")\n",
    "    #print(train_batch)\n",
    "    for state, action, reward, next_state, done in train_batch: #이 부분들 다시 한 번 보도록 하자 (3번째 Cell에 연습함)\n",
    "\n",
    "        Q = mainDQN_instance.predict(state)\n",
    "        Q_old = np.max(Q)\n",
    "        #DQN class module 만들어 놓은 거\n",
    "        #predict하면 각 action에따른 Q값이 나와야 하는거 아닌가?\n",
    "        \n",
    "        if done:\n",
    "            Q[0, action] = reward\n",
    "        else:\n",
    "            Q[0, action] = Q_old + alpha*(reward + dis*np.max(targetDQN_instance.predict(next_state)) - Q_old)\n",
    "            Q_new = Q[0, action]\n",
    "            #Error부분여기서 next_state가 next.state로 되어 있었음\n",
    "            \n",
    "        y_stack = np.vstack([y_stack, Q])\n",
    "        #ValueError: all the input array dimensions for the concatenation axis must match exactly, \n",
    "        #but along dimension 1, the array at index 0 has size 4 and the array at index 1 has size 2 <위에 생긴 문제>\n",
    "        x_stack = np.vstack([x_stack, state]) #state를 학습시키는거지 Q를 학습시키는건 아니다.\n",
    "        \n",
    "        #print(mainDQN_instance.update(x_stack, y_stack)) 출력해보면 그냥 하나의 array로 받아오는데,\n",
    "        loss, _ = mainDQN_instance.update(x_stack, y_stack)\n",
    "        \n",
    "    return loss, Q_old, Q_new\n",
    "    #return이 dqn.py module에서 loss를 결국 받아오도록 해놓았다.\n",
    "    #mainDQN_instance.update(x_stack, y_stack) --> self.session.run([self._loss, self._train], feed), loss와 train을 받아옴.\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "def copy_var_ops(*, dest_scope_name =\"target\", src_scope_name = \"main\"):\n",
    "\n",
    "    op_holder = []\n",
    "\n",
    "    src_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=src_scope_name)\n",
    "    dest_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=dest_scope_name)\n",
    "    \n",
    "    \n",
    "    for src_var, dest_var in zip(src_vars, dest_vars): #zip의 기능은?\n",
    "        op_holder.append(dest_var.assign(src_var.value()))\n",
    "        #dest_var(tensor). assign\n",
    "        \n",
    "    return op_holder\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    Q_old = np.empty(0)\n",
    "    Q_new = np.empty(0)  \n",
    "    st_step = 1 #action을 몇 time-step마다 취할 것인지에 대한 숫자\n",
    "    state_step = 0\n",
    "    record_frequency = 50\n",
    "    step_deadline = 3000\n",
    "    main_update_freq = 10\n",
    "    target_update_frequency = 40 \n",
    "    #main이 target을 향해서 update되어가고 이후에 target_update가 이루어져야 하기때문에 main_freq < target_update가 되어야 한다.\n",
    "    max_episodes = 500\n",
    "    \n",
    "    # Replay buffer를 deque로 짠다. \n",
    "    buffer = deque() \n",
    "    #Memory는 50000개까지 \n",
    "\n",
    "    reward_buffer = deque() #maxlen=100\n",
    "    #reward_buffer또한 deque로 만들어서 마지막 100개까지 기억하도록 한다\n",
    "    \n",
    "    reward_record = open(\"reward.plt\" , 'w', encoding='utf-8', newline='') \n",
    "    reward_record.write('VARIABLES = \"Episode\", \"Reward\" \\n') \n",
    "    #Reward를 기록하기 위함.\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        mainDQN = dqn.DQN(sess, input_size, output_size, name=\"main\") #Class로 mainDQN 하나 만들고\n",
    "        targetDQN = dqn.DQN(sess, input_size, output_size, name=\"target\") #Class로 targetDQN 하나 만들고\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # initial copy q_net -> target_net (copy하는 거) <처음에 targetDQN, mainDQN 임의로 설정이 되니까 같게 해줘야 한다>\n",
    "        copy_ops = copy_var_ops(dest_scope_name=\"target\",src_scope_name=\"main\")\n",
    "        #copy_var_ops는 위에 def 함수로 되어 있다.\n",
    "        sess.run(copy_ops)\n",
    "\n",
    "\n",
    "        for episode in range(0, max_episodes+1):\n",
    "            \n",
    "            print(\"Episode : {} start \".format(episode))\n",
    "\n",
    "            e = 1.0 / ((episode / 10) + 1)\n",
    "            done = False\n",
    "            state = environment.reset() #envrionment로부터 state를 가져온다. (초기 state)\n",
    "            reward_graph = 0\n",
    "            \n",
    "            \n",
    "            ############### 두개의 Neural network로 학습을 시키는 부분이다 ##########\n",
    "               \n",
    "            #정확히는 Episode 10이 끝난 시점에서 update하는 것이다.\n",
    "            if episode > main_update_freq and episode % main_update_freq == 0: # train every 10 episodes\n",
    "            #if len(buffer)>10 and len(buffer) % batch_size*5 == 0:\n",
    "                print(\"update start\") #check!\n",
    "                for _ in range(50):\n",
    "                # Minibatch works better\n",
    "                    #print(\"random_sample, step :{}\" ,format(_)) #check complete\n",
    "                    minibatch = random.sample(buffer, batch_size) \n",
    "                    minibatch = list(minibatch)\n",
    "                    #print(minibatch.shape) #check!\n",
    "                    #buffer에서 batch_size개수만큼씩 random하게 빼서 minibatch를 만든다.\n",
    "                    #print(\"go to replay_train\") #check complete\n",
    "                    loss, Q_old, Q_new= replay_train(mainDQN, targetDQN, minibatch)\n",
    "                \n",
    "                    #if episode == 1 :\n",
    "                    #print(minibatch)\n",
    "                        \n",
    "                    #Q_diff = abs(Q_old - Q_new)\n",
    "                    #print(\"\")\n",
    "                    #print(Q_diff, Q_old, Q_new) \n",
    "            ########################################################################\n",
    "            \n",
    "            if episode % record_frequency == 0:\n",
    "                record = environment.record_start(episode)\n",
    "                \n",
    "            while not done:\n",
    "                \n",
    "                if np.random.rand(1) < e:\n",
    "                    action = environment.random_action()\n",
    "                else:\n",
    "                    action = np.argmax(mainDQN.predict(state)) \n",
    "\n",
    "                # Get new state and reward from environment\n",
    "                \n",
    "                next_state, reward, done, record = environment.simulation(action, st_step, record)\n",
    "                \n",
    "                #한 step의 reward씩 계속 reward_graph에 쌓는다. summation of reward\n",
    "                reward_graph = reward + reward_graph\n",
    "                \n",
    "                if done:  \n",
    "                    reward = -10\n",
    "\n",
    "                ################ 이 부분이 Replay memory 부분이다 ##############\n",
    "                buffer.append((state, action, reward, next_state, done))\n",
    "                if len(buffer) > buffer_memory:\n",
    "                    buffer.popleft()\n",
    "                # buffer memory가 buffer_memory 이상이 되면 옛날 데이터는 빼버린다.\n",
    "                #print(\"buffer\") #check\n",
    "                #print(type(buffer))\n",
    "                \n",
    "                    \n",
    "                if state_step > 1 and state_step % target_update_frequency == 0:\n",
    "                    #print(\"update target\") #check complete\n",
    "                    sess.run(copy_ops)\n",
    "  \n",
    "                #print(\"update out\")   \n",
    "                ################################################################       \n",
    "               \n",
    "                state = next_state\n",
    "                \n",
    "                state_step = state_step + 1\n",
    "                #print(\"step num : {}\".format(step))\n",
    "                \n",
    "                if state_step == step_deadline:\n",
    "                    break\n",
    "       \n",
    "            reward_graph = reward_graph/state_step\n",
    "            \n",
    "            #plt file로 reward graph 저장\n",
    "            reward_record.write(\"%d %f \\n\" %(episode , reward_graph))\n",
    "        \n",
    "            state_step = 0\n",
    "            #print(\"Episode : {} end \".format(episode))\n",
    "            \n",
    "            \n",
    "            if episode % record_frequency == 0:\n",
    "                _ = environment.record_end(record)\n",
    "            # Episode (finish)\n",
    "            \n",
    "    reward_record.close()\n",
    "            \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #여기가 main 맞으니까 main이 실행되는거 맞는데 굳이 위와 같이 할 필요가 있나 싶은데?\n",
    "    main()\n",
    "    \n",
    "   \n",
    "    print(\"All process is finished!\")\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#First Error   \n",
    "# File \"C:\\Users\\thlee\\DQN (real)\\dqn.py\", line 34\n",
    "# W2 = tf.get_variable(\"W2\", shape = [h_size, self.h_size], initializer = tf.contrib.layers.xavier_initializer())\n",
    "#  ^ <위의 layer1 = tf.nn.tanh(tf.matmul(self._X, W1) <- 괄호 하나 빠져 있었음\n",
    "# SyntaxError: invalid syntax\n",
    "\n",
    "#Second ERROR\n",
    "#ValueError: Sample larger than population or is negative\n",
    "#뽑아낼게 전체 모집단보다 작으니까 뽑을게 없다는거잖아 아래 BATCH_SIZE를 64로 해서 그럼 이걸 줄여야함.\n",
    "#batch_size = 64 #Mini batch size Buffer에서 몇개씩 batch로 만들어서 학습시킬 것인가?\n",
    "#batch_size = 10으로 해보자.\n",
    "\n",
    "#Third Error\n",
    "# 위처럼 나타내면 결국 list - list로 되는 꼴인데\n",
    "#이때 이런 TypeError: unsupported operand type(s) for -: 'list' and 'list'가 나온다\n",
    "# 그 이유는 list는 -나 /에 정의되어 있지 않기때문이다.\n",
    "\n",
    "#Fourth Error\n",
    "#ValueError: not enough values to unpack (expected 4, got 3)    \n",
    "#argv variable contains command line arguments. \n",
    "#In your code you expected 4 arguments, but got only 3 (first argument always script name). \n",
    "\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
